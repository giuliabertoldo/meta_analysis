---
title: "Meta-analysis based on Sisks et al. (2018) - V.1"
author: "Giulia Bertoldo"
date: "4/7/2022"
output: 
  pdf_document:
    toc: true 
---


```{r}
# Load packages
library(tidyverse)
library(meta)
library(readxl)

# Import data
df1 <- read_excel('data/mindset.xlsx', sheet = 'Meta-analysis 1')
```

\newpage

# Data cleaning

```{r}
# Glimpse data
glimpse(df1)

# Rename columns
df2 <- rename(df1, 
             document_id = 'Document #', 
             study_id = 'Study #',
             sample_id = 'Sample #',
             sample_country = 'Sample Country',
             es_id = 'ES #',
             reference = 'Reference', 
             n = N, 
             adjusted_n = 'Adjusted N', 
             student_description = 'Student Description', 
             school_level = 'School Level', 
             development_stage = 'Development Stage', 
             risk_status = 'Risk status', 
             ses = SES, 
             ms_measure = 'MS Measure', 
             ms_measure_description = 'MS Measure Description', 
             mindset_type = 'Mindset Type', 
             achievement_measure_description = 'Achievement Measure Description', 
             academic_achievement_measure_type = 'Academic Achievement Measure Type',
             lab_based = 'Lab-based', 
             published = 'Published',
             es_type = 'ES type', 
             calculation = 'Calculation', 
             variance = 'Variance', 
             adjusted_variance = 'Adjusted Variance', 
             is_significant = 'Significant?', 
             growth_m = 'Growth M',
             growth_sd = 'Growth SD',
             other_m = 'Other M', 
             other_sd = 'Other SD', 
             cohen_d = "Cohen's d",
             calculated_r = 'Calculated r', 
             notes = Notes)
          

# Check that variable types is correct
glimpse(df2)

# Change school_level from character to factor 
df2$school_level <- as.factor(df2$school_level)
levels(df2$school_level)

# Change development_stage from character to factor
df2$development_stage <- as.factor(df2$development_stage)
levels(df2$development_stage)

# Convert all "Wide Range" level to "Wide range"
# Does not work! TOBEDONE
for (i in length(df2$development_stage)) {
  if (df2$development_stage[i] == 'Wide Range') {
    df2$development_stage[i] <- 'Wide range'}  
} 

# Change risk_status from character to factor
# TOBEDONE: What is the meaning of '.'? Change to NA?
df2$risk_status <- as.factor(df2$risk_status)
levels(df2$risk_status)

# Change ses from character to factor
df2$ses <- as.factor(df2$ses)
levels(df2$ses)

# Change mindset_type from character to factor
df2$mindset_type <- as.factor(df2$mindset_type)
levels(df2$mindset_type)

# Change academic_achievement_measure_type from character to factor
df2$academic_achievement_measure_type <- as.factor(df2$academic_achievement_measure_type)
levels(df2$academic_achievement_measure_type)

# Change lab_based from character to factor
df2$lab_based <- as.factor(df2$lab_based)
levels(df2$lab_based)

# Change published from character to factor
df2$published <- as.factor(df2$published)
levels(df2$published)

# Change es_type from character to factor
df2$es_type <- as.factor(df2$es_type)
levels(df2$es_type)

# Change is_significant from character to factor
df2$is_significant <- as.factor(df2$is_significant)
levels(df2$is_significant)

```

\newpage

# Meta-analysis 1

* REM

* REML to estimate tau 

* No hakn correction

```{r}
meta1 <- metacor(cor = r, 
                 n = n, 
                 studlab = reference, 
                 data= df2, 
                 fixed = FALSE, 
                 random = TRUE, 
                 method.tau = 'REML', 
                 hakn = FALSE, 
                 title = "Mindset and Academic Achievement", 
                 prediction = TRUE)
meta1
```
* `r meta1$k` studies were combined in the meta-analysis

* Estimated correlation is `r meta1$TE.random` with standard error  `r meta1$seTE.random` with 95% confidence interval [`r meta1$lower.random`, `r meta1$upper.random`], which excludes zero. 

\newpage

## Analysis of between-studies heterogeneity

* Cochrane's Q: If there was no heterogeneity this statistics should be distributed as a $\chi^2$ distribution with `r meta1$df.Q` degrees of freedom. In our meta-analysis $Q = $`r meta1$Q`. We reject the null hypothesis of homogeneity. There is evidence for heterogeneity. 

* $I^2 =$ `r meta1$I2`(95%CI:`r meta1$lower.I2`-`r meta1$lower.I2`%), meanining that about 97% of the variability in effect sizes is due between-study heterogeneity. This can be considered substantial heterogeneity (according to Thmppson's rule of thumb). 

* H, the square root of $H^2$, is `r meta1$H`. Values greater than 1 indicate heterogeneity. 

* $\tau^2$, the between-study variance or 'variance of the true effect size underlying our data', is `r meta1$tau2` with 95% confidence interval [`r meta1$lower.tau2`, `r meta1$upper.tau2`], which does not include zero. Indicates heterogeneity. The confidence interval for $\tau^2$ was calculated based on the Q-profile method.   

* $\tau$, is the 'standard deviation of the true effect size and [...] it tells us something about the range of the true effect sizes. The true effect sizes have an estimated standard deviation of $SD = $`r meta1$tau` expressed on the scale of correlation coefficient.

* The prediction interval ranges from $r =$ `r meta1$lower.predict` to `r meta1$upper.predict`. This means that it is possible that some future studies will find a negative correlation between mindset and academic achievement based on the present evidence. But the interval spans also over to a substantial positive effect. 
\newpage

## Outliers and influential cases 

### Basic outlier removal 

Function: 

```{r}
#' Find Statistical Outliers in a Meta-Analysis
#'
#' Searches for statistical outliers in meta-analysis results generated by \code{\link[meta]{meta}} functions or the
#' \code{\link[metafor]{rma.uni}} in the \code{metafor} package.
#'
#' @usage find.outliers(x, ...)
#'
#' @param x Either (1) an object of class \code{meta}, generated by the \code{metabin}, \code{metagen},
#' \code{metacont}, \code{metacor}, \code{metainc}, \code{metarate} or \code{metaprop} function; or (2)
#' and object of class \code{rma.uni} created with the \code{\link[metafor]{rma.uni}} function in \code{metafor}.
#' @param ... Additional parameters for the \code{\link[metafor]{rma.uni}} or \code{\link[meta]{update.meta}} function.
#'
#' @details
#' This function searches for outlying studies in a meta-analysis results object. Studies are defined as outliers when
#' their 95\% confidence interval lies ouside the 95\% confidence interval of the pooled effect.
#'
#' When outliers are found, the function automatically recalculates the meta-analysis results, using the same settings as
#' in the object provided in \code{x}, but excluding the detected outliers.
#'
#' A forest plot of the meta-analysis with outliers removed can be generated directly by plugging the output of the function into
#' the \code{forest} function.
#'
#' @references Harrer, M., Cuijpers, P., Furukawa, T.A, & Ebert, D. D. (2019).
#' \emph{Doing Meta-Analysis in R: A Hands-on Guide}. DOI: 10.5281/zenodo.2551803. \href{https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/detecting-outliers-influential-cases.html}{Chapter 6.2}
#'
#' @author Mathias Harrer & David Daniel Ebert
#'
#' @return
#' Returns the identified outliers and the meta-analysis results when the outliers are removed.
#'
#' If the provided meta-analysis object is of class \code{meta}, the following objects are returned if the
#' results of the function are saved to another object:
#' \itemize{
#' \item \code{out.study.fixed}: A numeric vector containing the names of the outlying studies when
#' assuming a fixed-effect model.
#' \item \code{out.study.random}: A numeric vector containing the names of the outlying studies when
#' assuming a random-effects model. The \eqn{\tau^{2}} estimator \code{method.tau} is inherited from \code{x}.
#' \item \code{m.fixed}: An object of class \code{meta} containing the results of the meta-analysis with outliers
#' removed (assuming a fixed-effect model).
#' \item \code{m.random}: An object of class \code{meta} containing the results of the meta-analysis with outliers
#' removed (assuming a random-effects model, and using the same \code{method.tau} as in the original analysis).
#'}
#'
#' If the provided meta-analysis object is of class \code{rma.uni}, the following objects are returned if the
#' results of the function are saved to another object:
#' \itemize{
#' \item \code{out.study}: A numeric vector containing the names of the outlying studies.
#' \item \code{m}: An object of class \code{rma.uni} containing the results of the meta-analysis with outliers
#' removed (using the same settings as in the meta-analysis object provided).
#'}
#' @importFrom metafor rma.uni
#' @importFrom meta update.meta
#'
#' @export find.outliers
#'
#' @aliases spot.outliers.random spot.outliers.fixed spot.outliers
#'
#' @seealso \code{\link[metafor]{influence.rma.uni}}, \code{\link[meta]{metainf}}, \code{\link[meta]{baujat}}
#'
#' @examples
#' suppressPackageStartupMessages(library(meta))
#' suppressPackageStartupMessages(library(metafor))
#' suppressPackageStartupMessages(library(dmetar))
#'
#' # Pool with meta
#' m1 <- metagen(TE, seTE, data = ThirdWave,
#'               studlab = ThirdWave$Author, comb.fixed = FALSE)
#'
#' # Pool with metafor
#' m2 <- rma(yi = TE, sei = seTE, data = ThirdWave,
#'           slab = ThirdWave$Author, method = "PM")
#'
#' # Find outliers
#' fo1 <- find.outliers(m1)
#' fo2 <- find.outliers(m2)
#'
#' # Show summary
#' summary(fo1)
#' summary(fo2)
#'
#' \dontrun{
#' # Make forest plot
#' # Pass additional arguments from meta & metafor's forest function
#' forest(fo1, prediction = TRUE)
#' forest(fo2, cex = .8, col = "lightblue")
#' }


find.outliers = spot.outliers.random = spot.outliers.fixed = function(x, ...){


  if (class(x)[1] %in% c("rma.uni", "rma")){

    token = "metafor"

    # Generate lower/upper for all effects
    lower = as.numeric(x$yi - 1.96*sqrt(x$vi))
    upper = as.numeric(x$yi + 1.96*sqrt(x$vi))

    # Select outliers
    mask = upper < x$ci.lb | lower > x$ci.ub
    dat = data.frame("yi" = x$yi[!mask],
                     "vi" = x$vi[!mask],
                     "studlab" = as.character(x$slab[!mask]))
    out.study = x$slab[mask]

    # Update metafor model
    method.tau = x$method
    m = metafor::rma.uni(dat$yi, vi = dat$vi, method = method.tau, slab = dat$studlab, ...)

    if (length(out.study) < 1){


      tau.token = "metafor.null"
      cat(paste0("No outliers detected (", method.tau,")."))
      out.study = NULL

    } else {

      tau.token = "metafor"

    }

  }

  if (class(x)[1] %in% c("metagen", "metapropr",
                         "metacor", "metainc", "metacont",
                         "metaprop", "metabin", "metabin")){

    token = "meta"

    # Control for objects with NAs in study data
    if (anyNA(x$TE) | anyNA(x$seTE)){
      warning("Studies with NAs not considered in outlier analysis.")

    }


    if (class(x)[1] == "metaprop"){

      lower = x$TE - 1.96*x$seTE
      upper = x$TE + 1.96*x$seTE

      # Generate mask with outliers (fixed/random)
      mask.fixed =
        (!is.na(upper) & upper < x$lower.fixed) |
        (!is.na(lower) & lower > x$upper.fixed)
      mask.random =
        (!is.na(upper) & upper < x$lower.random) |
        (!is.na(lower) & lower > x$upper.random)

    } else {

      # Generate mask with outliers (fixed/random)
      mask.fixed =
        (!is.na(x$upper) & x$upper < x$lower.fixed) |
        (!is.na(x$lower) & x$lower > x$upper.fixed)
      mask.random =
        (!is.na(x$upper) & x$upper < x$lower.random) |
        (!is.na(x$lower) & x$lower > x$upper.random)

    }

    # Update meta-analysis with outliers removed
    m.fixed = update.meta(x, exclude = mask.fixed, ...)
    m.random = update.meta(x, exclude = mask.random, ...)

    # Select names of outlying studies
    out.study.fixed = x$studlab[mask.fixed]
    out.study.random = x$studlab[mask.random]

    if (x$comb.fixed == TRUE & x$comb.random == FALSE){

      if (length(out.study.fixed) < 1){

        tau.token = "null.ftrf"
        out.study.fixed = NULL

      } else {

        tau.token = "ftrf"

      }

    }

    if (x$comb.fixed == FALSE & x$comb.random == TRUE){

      if (length(out.study.random) < 1){

        tau.token = "null.ffrt"
        out.study.random = NULL

      } else {

        tau.token = "ffrt"

      }

    }

    if (x$comb.fixed == TRUE & x$comb.random == TRUE){

      if (length(out.study.fixed) < 1 & length(out.study.random) < 1){

        out.study.fixed = NULL
        out.study.random = NULL
        tau.token = "null.ftrt"

      } else {

        if (length(out.study.fixed) < 1){out.study.fixed = NULL}
        if (length(out.study.random) < 1){out.study.random = NULL}

        tau.token = "ftrt"

      }

    }

  }

  if (!class(x)[1] %in% c("rma.uni", "rma", "metacont",
                          "metagen", "metapropr",
                          "metacor", "metainc",
                          "metaprop", "metabin", "metabin")){

    message("Input must be of class 'meta' or 'rma.uni'")

  }

  if (token == "metafor"){

    returnlist = list("out.study" = out.study,
                   "m" = m)

    if (tau.token == "metafor"){class(returnlist) = c("find.outliers", "mf", method.tau)}
    if (tau.token == "metafor.null"){class(returnlist) = c("find.outliers", "mf.null", method.tau)}

    # Return
    invisible(returnlist)

    returnlist

  } else {


    returnlist = list("out.study.fixed" = out.study.fixed,
                   "out.study.random" = out.study.random,
                   "m.fixed" = m.fixed,
                   "m.random" = m.random)

    # Set classes
    if (tau.token == "ftrf"){class(returnlist) = c("find.outliers", "ftrf")}
    if (tau.token == "ffrt"){class(returnlist) = c("find.outliers", "ffrt")}
    if (tau.token == "ftrt"){class(returnlist) = c("find.outliers", "ftrt")}
    if (tau.token == "null.ftrf"){class(returnlist) = c("find.outliers", "null.ftrf")}
    if (tau.token == "null.ffrt"){class(returnlist) = c("find.outliers", "null.ffrt")}
    if (tau.token == "null.ftrt"){class(returnlist) = c("find.outliers", "null.ftrt")}

    # Return
    invisible(returnlist)

    returnlist

  }

}
```

```{r}
find.outliers(meta1)
```

* 137 were identified: from 273 included studies, the anlaysis includes only 136

* I^2 moves from about 97% to 26.8%

* $tau^2$ is now closer to zero tau^2 = 0.0016 [0.0006; 0.0049]

* The Q statistics is still significant:  Q = 250.11, df = 183, p-value = 0.0007

* The estimated effect does not change substantialli: r = 0.1046, 95% CI [0.0916; 0.1175] 

\newpage

## Influence analysis 

Function: 

```{r}
#' Influence Diagnostics
#'
#' Conducts an influence analysis of a meta-analysis generated by \code{\link[meta]{meta}} functions,
#' and allows to produce influence diagnostic plots.
#'
#' @usage InfluenceAnalysis(x, random = FALSE, subplot.heights = c(30,18),
#'     subplot.widths = c(30,30), forest.lims = 'default',
#'     return.separate.plots = FALSE, text.scale = 1)
#'
#' @param x An object of class \code{meta}, generated by the \code{metabin}, \code{metagen},
#' \code{metacont}, \code{metacor}, \code{metainc}, \code{metarate} or \code{metaprop} function.
#' @param random Logical. Should the random-effects model be used to generate the influence diagnostics?
#' Uses the \code{method.tau} specified in the \code{meta} object if one
#' of "\code{DL}", "\code{HE}", "\code{SJ}", "\code{ML}", "\code{REML}", "\code{EB}", "\code{PM}", "\code{HS}" or "\code{GENQ}" (to ensure compatibility with
#' the \code{\link[metafor]{metafor}} package). Otherwise, the DerSimonian-Laird
#' (\code{"DL"}; DerSimonian & Laird, 1986) estimator is used. \code{FALSE} by default.
#' @param subplot.heights Concatenated array of two numerics. Specifies the heights of the
#' first (first number) and second (second number) row of the overall plot generated when plotting the results.
#' Default is \code{c(30,18)}.
#' @param subplot.widths Concatenated array of two numerics. Specifies the widths of the
#' first (first number) and second (second number) column of the overall results plot generated when plotting the results.
#' Default is \code{c(30,30)}.
#' @param forest.lims Concatenated array of two numerics. Specifies the x-axis limits of the forest plots
#' generated when plotting the results. Use \code{"default"} if standard settings should be used (this is the default).
#' @param return.separate.plots Logical. When plotted, should the influence plots be shown as separate plots in lieu
#' of returning them in one overall plot?
#' @param text.scale Positive numeric. Scaling factor for the text geoms used when plotting the results. Values <1 shrink the
#' text, while values >1 increase the text size. Default is \code{1}.
#'
#' @details
#' The function conducts an influence analysis using the "Leave-One-Out" paradigm internally
#' and produces data for four influence diagnostics. Diagnostic plots can be produced by saving the output of the
#' function to an object and plugging it into the \code{plot} function.
#' These diagnostics may be used to determine which study or effect size
#' may have an excessive influence on the overall results of a meta-analysis and/or contribute substantially to
#' the between-study heterogeneity in an analysis. This may be used for outlier detection and to test
#' the robustness of the overall results found in an analysis. Results for four diagnostics are calculated:
#' \itemize{
#' \item \strong{Baujat Plot}: Baujat et al. (2002) proposed a plot to evaluate heterogeneity patterns in
#' a meta-analysis. The x-axis of the Baujat plot shows the overall heterogeneity contribution of each effect size
#' while the y-axis shows the influence of each effect size on the pooled result. The \code{\link[meta]{baujat}}
#' function is called internally to produce the results. Effect sizes or studies with high values
#' on both the x and y-axis may be considered to be influential cases; effect sizes or studies
#' with high heterogeneity contribution (x-axis) and low influence on the overall results can be outliers
#' which might be deleted to reduce the amount of between-study heterogeneity.
#' \item \strong{Influence Characteristics}: Several influence analysis diagnostics
#' proposed by Viechtbauer & Cheung (2010). Results are calculated by an internal call
#' to \code{\link[metafor]{influence.rma.uni}}. In the console output, potentially influential studies are marked
#' with an asterisk (\code{*}). When plotted, effect sizes/studies determined to be influential cases
#' using the "rules of thumb" described in Viechtbauer & Cheung (2010) are shown in red. For further
#' details, see the documentation of the \code{\link[metafor]{influence.rma.uni}} function.
#' \item \strong{Forest Plot for the Leave-One-Out Analysis, sorted by Effect Size}: This
#' displays the effect size and \eqn{I^2}-heterogeneity when omitting one of the \eqn{k} studies each time.
#' The plot is sorted by effect size to determine which studies or effect sizes particularly
#' affect the overall effect size. Results are generated by an internal call to \code{\link[meta]{metainf}}.
#' \item \strong{Forest Plot for the Leave-One-Out Analysis, sorted by \eqn{I^2}}: see above; results are sorted
#' by \eqn{I^2} to determine the study for which exclusion results in the greatest reduction of heterogeneity.
#'}
#'
#' @references Harrer, M., Cuijpers, P., Furukawa, T.A, & Ebert, D. D. (2019).
#' \emph{Doing Meta-Analysis in R: A Hands-on Guide}. DOI: 10.5281/zenodo.2551803. \href{https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/influenceanalyses.html}{Chapter 6.3}
#'
#' DerSimonian R. & Laird N. (1986), Meta-analysis in clinical trials. \emph{Controlled Clinical Trials, 7}, 177–188.
#'
#' Viechtbauer, W., & Cheung, M. W.-L. (2010). Outlier and influence diagnostics for meta-analysis. \emph{Research Synthesis Methods, 1}, 112–125.
#'
#' @author Mathias Harrer & David Daniel Ebert
#'
#' @return A \code{list} object of class \code{influence.analysis} containing the
#' following objects is returned (if results are saved to a variable):
#' \itemize{
#' \item \code{BaujatPlot}: The Baujat plot
#' \item \code{InfluenceCharacteristics}: The Viechtbauer-Cheung influence characteristics plot
#' \item \code{ForestEffectSize}: The forest plot sorted by effect size
#' \item \code{ForestI2}: The forest plot sorted by between-study heterogeneity
#' \item \code{Data}: A \code{data.frame} containing the data used for plotting.
#'}
#' Otherwise, the function prints out (1) the results of the Leave-One-Out Analysis (sorted by \eqn{I^2}),
#' (2) the Viechtbauer-Cheung Influence Diagnostics and  (3) Baujat Plot data (sorted by heterogeneity contribution),
#' in this order. Plots can be produced manually by plugging a saved object of class \code{InfluenceAnalysis} generated by
#' the function into the \code{plot} function. It is also possible to only produce one specific plot by
#' specifying the name of the plot as a \code{character} in the second argument of the \code{plot} call (see Examples).
#'
#' @import ggplot2 ggrepel grid
#' @importFrom gridExtra grid.arrange arrangeGrob
#' @importFrom metafor rma.uni influence.rma.uni
#' @importFrom meta metainf
#' @importFrom graphics abline axis lines mtext par plot points rect segments text
#' @importFrom stats as.formula hat influence ks.test optimize pbinom pchisq pf pnorm pt punif qchisq qf qnorm qt reformulate reorder setNames uniroot
#'
#' @export InfluenceAnalysis
#'
#' @seealso \code{\link[metafor]{influence.rma.uni}}, \code{\link[meta]{metainf}}, \code{\link[meta]{baujat}}
#'
#' @examples
#'
#' \dontrun{
#' # Load 'ThirdWave' data
#' data(ThirdWave)
#'
#' # Create 'meta' meta-analysis object
#' suppressPackageStartupMessages(library(meta))
#' meta = metagen(TE, seTE, studlab = paste(ThirdWave$Author), data=ThirdWave)
#'
#' # Run influence analysis; specify to return separate plots when plotted
#' inf.an = InfluenceAnalysis(meta, return.separate.plots = TRUE)
#'
#' # Show results in console
#' inf.an
#'
#' # Generate all plots
#' plot(inf.an)
#'
#' # For baujat plot
#' plot(inf.an, "baujat")
#'
#' # For influence diagnostics plot
#' plot(inf.an, "influence")
#'
#' # For forest plot sorted by effect size
#' plot(inf.an, "ES")
#'
#' # For forest plot sorted by I-squared
#' plot(inf.an, "I2")}


### Influence Analysis function for fixed-effect-model meta-analyses

InfluenceAnalysis = function(x, random = FALSE, subplot.heights = c(30, 18),
                             subplot.widths = c(30, 30),
                             forest.lims = "default", return.separate.plots = FALSE,
                             text.scale = 1) {

    # Validate
    x = x
    if (class(x)[1] %in% c("meta", "metabin", "metagen", "metacont", "metacor", "metainc", "metaprop", "metarate")) {
      x <- update(x, subset = !(is.na(x$TE) | is.na(x$seTE)))
    } else {

        stop("Object 'x' must be of class 'meta', 'metabin', 'metagen', 'metacont', 'metacor', 'metainc', or 'metaprop'")
    }

    n.studies = x$k
    TE = x$TE
    seTE = x$seTE
    random = random

    # Make unique studlabs
    x$studlab = make.unique(x$studlab)

    if (random %in% c(TRUE, FALSE)) {


    } else {

        stop("'random' must be set to either TRUE or FALSE.")
    }

    forest.lims = forest.lims

    if (forest.lims[1] == "default" | (class(forest.lims[1]) == "numeric" & class(forest.lims[2]) == "numeric")) {

    } else {
        stop("'forest.lims' must either be 'default' or two concatenated numerics for ymin and ymax.")
    }

    return.seperate.plots = return.separate.plots

    if (return.seperate.plots %in% c(TRUE, FALSE)) {


    } else {

        stop("'return.separate.plots' must be set to either TRUE or FALSE.")
    }


    heights = subplot.heights
    if (class(heights[1]) == "numeric" & class(heights[2]) == "numeric") {

    } else {
        stop("'subplot.heights' must be two concatenated numerics.")
    }


    widths = subplot.widths
    if (class(widths[1]) == "numeric" & class(widths[2]) == "numeric") {

    } else {
        stop("'widths' must be two concatenated numerics.")
    }

    text.scale = text.scale
    if (text.scale > 0) {

    } else {
        stop("'text.scale' must be a single number greater 0.")
    }

    if (length(unique(x$studlab)) != length(x$studlab)) {
        stop("'Study labels in the 'meta' object must be unique.")
    }

    ########################################
    cat("[===============")
    ########################################

    if (random == FALSE) {
        method.rma = "FE"
        method.meta = "fixed"
    } else {
        if (x$method.tau %in% c("DL", "HE", "SJ", "ML", "REML", "EB", "HS", "GENQ", "PM")) {
            method.rma = x$method.tau
        } else {
            method.rma = "DL"
            cat("Tau estimator is unkown to metafor::rma; DerSimonian-Laird ('DL') estimator used.")
        }
        method.meta = "random"
    }

    # Perform Meta-Analysis using metafor, get influence results
    res = metafor::rma.uni(yi = TE, sei = seTE, measure = "GEN", data = x, method = method.rma, slab = studlab)
    metafor.inf = influence(res)
    # Recode inf
    metafor.inf$is.infl = ifelse(metafor.inf$is.infl == TRUE, "yes", "no")
    cheungviechtdata = cbind(study = substr(rownames(as.data.frame(metafor.inf$inf)), 1, 3), as.data.frame(metafor.inf$inf), is.infl = metafor.inf$is.infl)
    rownames(cheungviechtdata) = NULL

    if (length(unique(cheungviechtdata$study)) < length(cheungviechtdata$study)) {

        i = 3

        while (length(unique(cheungviechtdata$study)) < length(cheungviechtdata$study)) {

            i = i + 1
            cheungviechtdata$study = substr(rownames(as.data.frame(metafor.inf$inf)), 1, i)

        }


    }

    # If study labels are only numeric: reset level indexing
    if (sum(grepl("[A-Za-z]", levels(as.factor(cheungviechtdata$study)), perl = T)) == 0){

      cheungviechtdata$study = factor(cheungviechtdata$study, levels = sort(as.numeric(levels(cheungviechtdata$study))))

    }



    ########################################
    cat("===============")
    ########################################

    scalefun = function(x) sprintf("%.1f", x)

    cheungviechtdata = as.data.frame(cheungviechtdata)

    # Generate plots
    rstudent.plot = ggplot2::ggplot(cheungviechtdata, aes(y = rstudent, x = study, color = is.infl, group = 1)) +
        geom_line(color = "black") + geom_point(size = 2) + scale_color_manual(values = c("blue", "red")) +
        theme_minimal() + theme(axis.title.x = element_blank(), legend.position = "none", axis.text.x = element_text(angle = 45,
        size = 5), axis.title.y = element_text(size = 7), axis.text.y = element_text(size = 5)) + ylab("Stand. Residual") +
        scale_y_continuous(labels = scalefun)

    dffits.thresh = 3 * sqrt(metafor.inf$p/(metafor.inf$k - metafor.inf$p))
    dffits.plot = ggplot2::ggplot(cheungviechtdata, aes(y = dffits, x = study, color = is.infl, group = 1)) +
        geom_line(color = "black") + geom_point(size = 2) + scale_color_manual(values = c("blue", "red")) +
        theme_minimal() + theme(axis.title.x = element_blank(), legend.position = "none", axis.text.x = element_text(angle = 45,
        size = 5), axis.title.y = element_text(size = 7), axis.text.y = element_text(size = 5)) + ylab("DFFITS") +
        scale_y_continuous(labels = scalefun)
    # geom_hline(yintercept = dffits.thresh, linetype='dashed', color='black')

    cook.d.plot = ggplot2::ggplot(cheungviechtdata, aes(y = cook.d, x = study, color = is.infl, group = 1)) +
        geom_line(color = "black") + geom_point(size = 2) + scale_color_manual(values = c("blue", "red")) +
        theme_minimal() + theme(axis.title.x = element_blank(), legend.position = "none", axis.text.x = element_text(angle = 45,
        size = 5), axis.title.y = element_text(size = 7), axis.text.y = element_text(size = 5)) + ylab("Cook's Distance") +
        scale_y_continuous(labels = scalefun)

    cov.r.plot = ggplot2::ggplot(cheungviechtdata, aes(y = cov.r, x = study, color = is.infl, group = 1)) +
        geom_line(color = "black") + geom_point(size = 2) + scale_color_manual(values = c("blue", "red")) +
        theme_minimal() + theme(axis.title.x = element_blank(), legend.position = "none", axis.text.x = element_text(angle = 45,
        size = 5), axis.title.y = element_text(size = 7), axis.text.y = element_text(size = 5)) + ylab("Covariance Ratio") +
        scale_y_continuous(labels = scalefun)

    tau2.del.plot = ggplot2::ggplot(cheungviechtdata, aes(y = tau2.del, x = study, color = is.infl, group = 1)) +
        geom_line(color = "black") + geom_point(size = 2) + scale_color_manual(values = c("blue", "red")) +
        theme_minimal() + theme(axis.title.x = element_blank(), legend.position = "none", axis.text.x = element_text(angle = 45,
        size = 5), axis.title.y = element_text(size = 7), axis.text.y = element_text(size = 5)) + ylab("tau-squared (L-0-0)") +
        scale_y_continuous(labels = scalefun)

    QE.del.plot = ggplot2::ggplot(cheungviechtdata, aes(y = QE.del, x = study, color = is.infl, group = 1)) +
        geom_line(color = "black") + geom_point(size = 2) + scale_color_manual(values = c("blue", "red")) +
        theme_minimal() + theme(axis.title.x = element_blank(), legend.position = "none", axis.text.x = element_text(angle = 45,
        size = 5), axis.title.y = element_text(size = 7), axis.text.y = element_text(size = 5)) + ylab("Q (L-0-0)") +
        scale_y_continuous(labels = scalefun)

    hat.thresh = 3 * (metafor.inf$p/metafor.inf$k)
    hat.plot = ggplot2::ggplot(cheungviechtdata, aes(y = hat, x = study, color = is.infl, group = 1)) + geom_line(color = "black") +
        geom_point(size = 2) + scale_color_manual(values = c("blue", "red")) + theme_minimal() + theme(axis.title.x = element_blank(),
        legend.position = "none", axis.text.x = element_text(angle = 45, size = 5), axis.title.y = element_text(size = 7),
        axis.text.y = element_text(size = 5)) + ylab("hat") + scale_y_continuous(labels = scalefun)
    # geom_hline(yintercept = hat.thresh, linetype='dashed', color='black')

    weight.plot = ggplot2::ggplot(cheungviechtdata, aes(y = weight, x = study, color = is.infl, group = 1)) +
        geom_line(color = "black") + geom_point(size = 2) + scale_color_manual(values = c("blue", "red")) +
        theme_minimal() + theme(axis.title.x = element_blank(), legend.position = "none", axis.text.x = element_text(angle = 45,
        size = 5), axis.title.y = element_text(size = 7), axis.text.y = element_text(size = 5)) + ylab("weight") +
        scale_y_continuous(labels = scalefun)

    rma.influence.plot = arrangeGrob(rstudent.plot, dffits.plot, cook.d.plot, cov.r.plot, tau2.del.plot, QE.del.plot,
        hat.plot, weight.plot, ncol = 2)

    # Perform Influence Analysis on meta object, generate forests
    meta.inf = meta::metainf(x, pooled = method.meta)

    if (x$sm %in% c("RR", "OR", "IRR")) {

        effect = x$sm
        n.studies = n.studies

        # Create Sortdat data set for sorting
        sortdat = data.frame(studlab = meta.inf$studlab, mean = exp(meta.inf$TE), lower = exp(meta.inf$lower),
            upper = exp(meta.inf$upper), i2 = meta.inf$I2)
        sortdat2 = sortdat[1:(nrow(sortdat) - 2), ]
        lastline = sortdat[nrow(sortdat), ]

        # Change summary label
        if (random == TRUE) {
            lastline[1] = "Random-Effects Model"
        } else {
            lastline[1] = "Fixed-Effect Model"
        }

        for (i in 2:4) {
            lastline[i] = format(round(lastline[i], 2), nsmall = 2)
        }

        # Sort
        sortdat.es = sortdat2[order(sortdat2$mean), ]
        sortdat.es$studlab = factor(sortdat.es$studlab,
                                    levels = sortdat.es$studlab[order(-sortdat.es$mean)])
        sortdat.i2 = sortdat2[order(sortdat2$i2), ]
        sortdat.i2$studlab = factor(sortdat.i2$studlab,
                                    levels = sortdat.i2$studlab[order(-sortdat.i2$i2)])

        # Generate Forest Plots
        if (forest.lims[1] == "default") {

          if (min(sortdat.es$lower) > 0.5){
            min = 0.5
          } else {
            min = NA
          }

          if (max(sortdat.es$upper) <= 1){
            max = 1.2
          } else {
            max = round(max(sortdat.es$upper) + 6, 0)
          }

        } else {

          if (forest.lims[1] <= 0){
            min = NA
          } else {
            min = forest.lims[1]
          }
            max = forest.lims[2] + 4
        }

        if (method.meta == "fixed"){
          plot.sum.effect = exp(x$TE.fixed)
          plot.sum.lower =  exp(x$lower.fixed)
          plot.sum.upper =  exp(x$upper.fixed)
        } else {
          plot.sum.effect = exp(x$TE.random)
          plot.sum.lower =  exp(x$lower.random)
          plot.sum.upper =  exp(x$upper.random)
        }

        ########################################
        cat("===============")
        ########################################

        title.es = with(sortdat.es, {
          paste0("hat(theta)['*']~'='~", paste0("'", format(round(mean, 2)), "'"),
                 "~'['*", paste0("'", format(round(lower, 2), nsmall = 2), "'"), "*'-'*",
                 paste0("'", format(round(upper, 2), nsmall = 2), "'"), "*']'*';'~italic(I)^2~'='~",
                 paste0("'", format(round(i2, 2)*100,nsmall = 0), "'"), "*'%'")})

        title.i2 = with(sortdat.i2,{
          paste0("italic(I)^2~'='~",
                 paste0("'", format(round(i2, 2)*100,nsmall = 0), "'"), "*'%'", "*';'~",
                 "hat(theta)['*']~'='~", paste0("'", format(round(mean, 2)), "'"),
                 "~'['*", paste0("'", format(round(lower, 2), nsmall = 2), "'"), "*'-'*",
                 paste0("'", format(round(upper, 2), nsmall = 2), "'"), "*']'")})

        forest.es = ggplot(sortdat.es, aes(x = studlab, y = mean, ymin = lower, ymax = upper)) +
            geom_text(aes(label = title.es, y = Inf), parse = T, hjust = "inward", size = 3 * text.scale) + geom_hline(yintercept = 1,
            color = "blue") + ylab(paste(effect, " (", as.character(lastline$studlab), ")", sep = "")) + ggtitle("Sorted by Effect Size") +
            coord_flip() + theme_minimal() + theme(axis.title.y = element_blank(), axis.title.x = element_text(color = "black",
            size = 12, face = "bold"), axis.text.y = element_text(color = "black", size = 9 * text.scale),
            plot.title = element_text(face = "bold", hjust = 0.5), axis.line.x = element_line(color = "black"),
            axis.ticks.x = element_line(color = "black"), axis.text.x = element_text(color = "black", size = 9 *
                text.scale)) + scale_y_continuous(trans = "log2", limits = c(min, max)) +
          geom_rect(aes(ymin=plot.sum.lower, ymax=plot.sum.upper, xmin=0, xmax=Inf), alpha=0.08, fill="lightgreen", color=NA) +
          geom_hline(yintercept = plot.sum.effect, color = "darkgreen", linetype="dotted", size=0.5) +
          geom_point(shape = 15, size = 4.5, color = "grey") +
          geom_linerange(size = 0.9) +
          geom_pointrange(shape = 3, size = 0.3)

        forest.i2 = ggplot(sortdat.i2, aes(x = studlab, y = mean, ymin = lower, ymax = upper)) +
            geom_text(aes(label = title.i2, y = Inf), parse = T, hjust = "inward", size = 3 * text.scale) + geom_hline(yintercept = 1,
            color = "blue") + ylab(paste(effect, " (", as.character(lastline$studlab), ")", sep = "")) + ggtitle(expression(Sorted~by~italic(I)^2)) +
            coord_flip() + theme_minimal() + theme(axis.title.y = element_blank(), axis.title.x = element_text(color = "black",
            size = 12, face = "bold"), axis.text.y = element_text(color = "black", size = 9 * text.scale),
            plot.title = element_text(face = "bold", hjust = 0.5), axis.line.x = element_line(color = "black"),
            axis.ticks.x = element_line(color = "black"), axis.text.x = element_text(color = "black", size = 9 *
                text.scale)) + scale_y_continuous(trans = "log2", limits = c(min, max)) +
          geom_rect(aes(ymin=plot.sum.lower, ymax=plot.sum.upper, xmin=0, xmax=Inf), alpha=0.08, fill="lightgreen", color=NA) +
          geom_hline(yintercept = plot.sum.effect, color = "darkgreen", linetype="dotted", size=0.5) +
          geom_point(shape = 15, size = 4.5, color = "grey") +
          geom_linerange(size = 0.9) +
          geom_pointrange(shape = 3, size = 0.3)


    } else if (class(x)[1] %in% c("metacor", "metaprop", "metarate")) {

      effect = x$sm
      n.studies = n.studies

      # Create Sortdat data set for sorting
      sortdat = data.frame(studlab = meta.inf$studlab, mean = meta.inf$TE, lower = meta.inf$lower,
                           upper = meta.inf$upper, i2 = meta.inf$I2)
      sortdat2 = sortdat[1:(nrow(sortdat) - 2), ]
      lastline = sortdat[nrow(sortdat), ]

      # Change summary label
      if (random == TRUE) {
        lastline[1] = "Random-Effects Model"
      } else {
        lastline[1] = "Fixed-Effect Model"
      }

      for (i in 2:4) {
        lastline[i] = format(round(lastline[i], 2), nsmall = 2)
      }

      # Sort
      sortdat.es = sortdat2[order(sortdat2$mean), ]
      sortdat.es$studlab = factor(sortdat.es$studlab,
                                  levels = sortdat.es$studlab[order(-sortdat.es$mean)])
      sortdat.i2 = sortdat2[order(sortdat2$i2), ]
      sortdat.i2$studlab = factor(sortdat.i2$studlab,
                                  levels = sortdat.i2$studlab[order(-sortdat.i2$i2)])

      # Backtransform
      backtransformer = function(x, sm, n){

        # Define functions
        z2cor = function(x)
        {
          res <- (exp(2 * x) - 1)/(exp(2 * x) + 1)
          res
        }

        logit2p = function(x)
        {
          res <- 1/(1 + exp(-x))
          res
        }

        asin2p = function (x, n = NULL, value = "mean", warn = TRUE)
        {
          if (all(is.na(x)))
            return(x)
          if (is.null(n)) {
            minimum <- asin(sqrt(0))
            maximum <- asin(sqrt(1))
          }
          else {
            minimum <- 0.5 * (asin(sqrt(0/(n + 1))) + asin(sqrt((0 +
                                                                   1)/(n + 1))))
            maximum <- 0.5 * (asin(sqrt(n/(n + 1))) + asin(sqrt((n +
                                                                   1)/(n + 1))))
          }
          sel0 <- x < minimum
          sel1 <- x > maximum
          if (any(sel0, na.rm = TRUE)) {
            if (is.null(n)) {
              if (warn)
                warning("Negative value for ", if (length(x) >
                                                   1)
                  "at least one ", if (value == "mean")
                    "transformed proportion using arcsine transformation.\n  Proportion set to 0.",
                  if (value == "lower")
                    "lower confidence limit using arcsine transformation.\n  Lower confidence limit set to 0.",
                  if (value == "upper")
                    "upper confidence limit using arcsine transformation.\n  Upper confidence limit set to 0.",
                  sep = "")
            }
            else {
              if (warn)
                warning("Too small value for ", if (length(x) >
                                                    1)
                  "at least one ", if (value == "mean")
                    "transformed proportion using Freeman-Tukey double arcsine transformation.\n  Proportion set to 0.",
                  if (value == "lower")
                    "lower confidence limit using Freeman-Tukey double arcsine transformation.\n  Lower confidence limit set to 0.",
                  if (value == "upper")
                    "upper confidence limit using Freeman-Tukey double arcsine transformation.\n  Upper confidence limit set to 0.",
                  sep = "")
            }
          }
          if (any(sel1, na.rm = TRUE)) {
            if (is.null(n)) {
              if (warn)
                warning("Too large value for ", if (length(x) >
                                                    1)
                  "at least one ", if (value == "mean")
                    "transformed proportion using arcsine transformation.\n  Proportion set to 1.",
                  if (value == "lower")
                    "lower confidence limit using arcsine transformation.\n  Lower confidence limit set to 1.",
                  if (value == "upper")
                    "upper confidence limit using arcsine transformation.\n  Upper confidence limit set to 1.",
                  sep = "")
            }
            else {
              if (warn)
                warning("Too large value for ", if (length(x) >
                                                    1)
                  "at least one ", if (value == "mean")
                    "transformed proportion using Freeman-Tukey double arcsine transformation.\n  Proportion set to 1.",
                  if (value == "lower")
                    "lower confidence limit using Freeman-Tukey double arcsine transformation.\n  Lower confidence limit set to 1.",
                  if (value == "upper")
                    "upper confidence limit using Freeman-Tukey double arcsine transformation.\n  Upper confidence limit set to 1.",
                  sep = "")
            }
          }
          res <- rep(NA, length(x))
          sel <- !(sel0 | sel1)
          sel <- !is.na(sel) & sel
          res[sel0] <- 0
          res[sel1] <- 1
          if (is.null(n)) {
            res[sel] <- sin(x[sel])^2
          }
          else {
            res[sel] <- 0.5 * (1 - sign(cos(2 * x[sel])) * sqrt(1 -
                                                                  (sin(2 * x[sel]) + (sin(2 * x[sel]) - 1/sin(2 * x[sel]))/n[sel])^2))
          }
          res
        }

        asin2ir = function (x, time = NULL, value = "mean", warn = TRUE)
        {
          if (all(is.na(x)))
            return(x)
          minimum <- 0.5 * (sqrt(0/time) + sqrt((0 + 1)/time))
          sel0 <- x < minimum
          if (any(sel0, na.rm = TRUE)) {
            if (warn)
              warning("Too small value for ", if (length(x) > 1)
                "at least one ", if (value == "mean")
                  "transformed proportion using Freeman-Tukey double arcsine transformation.\n  Rate set to 0.",
                if (value == "lower")
                  "lower confidence limit using Freeman-Tukey double arcsine transformation.\n  Lower confidence limit set to 0.",
                if (value == "upper")
                  "upper confidence limit using Freeman-Tukey double arcsine transformation.\n  Upper confidence limit set to 0.",
                sep = "")
          }
          res <- rep(NA, length(x))
          sel <- !sel0
          sel <- !is.na(sel) & sel
          res[sel0] <- 0
          res[sel] <- (1/time[sel] - 8 * x[sel]^2 + 16 * time[sel] *
                         x[sel]^4)/(16 * x[sel]^2 * time[sel])
          res[res < 0] <- 0
          res
        }

        if(sm == "COR"){
          res = x
        }

        if(sm == "IR"){
          res = x
        }

        if(sm == "PRAW"){
          res = x
        }

        if(sm == "ZCOR"){
          res = z2cor(x)
        }

        if(sm == "PLOGIT"){
          res = logit2p(x)
        }

        if (sm == "PAS"){
          res <- asin2p(x, value = value, warn = FALSE)
        }

        if (sm == "PFT"){
          res = asin2p(x, n, value = value, warn = FALSE)
        }

        if (sm == "IRS"){
          res = x^2
        }

        if (sm == "IRFT"){
          res = asin2ir(x, time=n, value = value, warn = FALSE)
        }

        if (sm == "IRLN"){
          res = exp(x)
        }

        if (sm == "PLN"){
          res = exp(x)
        }

        res

      }

      if (class(x)[1] %in% c("metaprop", "metacor")){
        n.h.m = meta.inf$n.harmonic.mean[1:(length(meta.inf$n.harmonic.mean)-2)]
        n.h.m.tot = meta.inf$n.harmonic.mean[length(meta.inf$n.harmonic.mean)]
        n.h.m.es = n.h.m[order(sortdat.es$mean)]
        n.h.m.i2 = n.h.m[order(sortdat.i2$mean)]
        sortdat.es$mean = backtransformer(sortdat.es$mean, sm=effect, n=n.h.m.es)
        sortdat.es$lower = backtransformer(sortdat.es$lower, sm=effect, n=n.h.m.es)
        sortdat.es$upper = backtransformer(sortdat.es$upper, sm=effect, n=n.h.m.es)
        sortdat.i2$mean = backtransformer(sortdat.i2$mean, sm=effect, n=n.h.m.i2)
        sortdat.i2$lower = backtransformer(sortdat.i2$lower, sm=effect, n=n.h.m.i2)
        sortdat.i2$upper = backtransformer(sortdat.i2$upper, sm=effect, n=n.h.m.i2)

        if (method.meta == "fixed"){
          plot.sum.effect = backtransformer(x$TE.fixed, sm=effect, n=n.h.m.tot)
          plot.sum.lower = backtransformer(x$lower.fixed, sm=effect, n=n.h.m.tot)
          plot.sum.upper = backtransformer(x$upper.fixed, sm=effect, n=n.h.m.tot)
        } else {
          plot.sum.effect = backtransformer(x$TE.random, sm=effect, n=n.h.m.tot)
          plot.sum.lower = backtransformer(x$lower.random, sm=effect, n=n.h.m.tot)
          plot.sum.upper = backtransformer(x$upper.random, sm=effect, n=n.h.m.tot)
        }


      } else {

        if(meta.inf$sm == "IRFT"){
          n.h.m = meta.inf$t.harmonic.mean[1:(length(meta.inf$t.harmonic.mean)-2)]
          n.h.m.es = n.h.m[order(sortdat.es$mean)]
          n.h.m.i2 = n.h.m[order(sortdat.i2$mean)]
          n.h.m.tot = meta.inf$t.harmonic.mean[length(meta.inf$t.harmonic.mean)]
          sortdat.es$mean = backtransformer(sortdat.es$mean, sm=effect, n=n.h.m.es)
          sortdat.es$lower = backtransformer(sortdat.es$lower, sm=effect, n=n.h.m.es)
          sortdat.es$upper = backtransformer(sortdat.es$upper, sm=effect, n=n.h.m.es)
          sortdat.i2$mean = backtransformer(sortdat.i2$mean, sm=effect, n=n.h.m.i2)
          sortdat.i2$lower = backtransformer(sortdat.i2$lower, sm=effect, n=n.h.m.i2)
          sortdat.i2$upper = backtransformer(sortdat.i2$upper, sm=effect, n=n.h.m.i2)

          if (method.meta == "fixed"){
            plot.sum.effect = backtransformer(x$TE.fixed, sm=effect, n=n.h.m.tot)
            plot.sum.lower = backtransformer(x$lower.fixed, sm=effect, n=n.h.m.tot)
            plot.sum.upper = backtransformer(x$upper.fixed, sm=effect, n=n.h.m.tot)
          } else {
            plot.sum.effect = backtransformer(x$TE.random, sm=effect, n=n.h.m.tot)
            plot.sum.lower = backtransformer(x$lower.random, sm=effect, n=n.h.m.tot)
            plot.sum.upper = backtransformer(x$upper.random, sm=effect, n=n.h.m.tot)
          }


        } else {
          n.h.m.tot = meta.inf$n.harmonic.mean[length(meta.inf$n.harmonic.mean)]
          sortdat.es$mean = backtransformer(sortdat.es$mean, sm=effect, n=NULL)
          sortdat.es$lower = backtransformer(sortdat.es$lower, sm=effect, n=NULL)
          sortdat.es$upper = backtransformer(sortdat.es$upper, sm=effect, n=NULL)
          sortdat.i2$mean = backtransformer(sortdat.i2$mean, sm=effect, n=NULL)
          sortdat.i2$lower = backtransformer(sortdat.i2$lower, sm=effect, n=NULL)
          sortdat.i2$upper = backtransformer(sortdat.i2$upper, sm=effect, n=NULL)

          if (method.meta == "fixed"){
            plot.sum.effect = backtransformer(x$TE.fixed, sm=effect, n=n.h.m.tot)
            plot.sum.lower = backtransformer(x$lower.fixed, sm=effect, n=n.h.m.tot)
            plot.sum.upper = backtransformer(x$upper.fixed, sm=effect, n=n.h.m.tot)
          } else {
            plot.sum.effect = backtransformer(x$TE.random, sm=effect, n=n.h.m.tot)
            plot.sum.lower = backtransformer(x$lower.random, sm=effect, n=n.h.m.tot)
            plot.sum.upper = backtransformer(x$upper.random, sm=effect, n=n.h.m.tot)
          }

        }
      }


      # Generate Forest Plots
      if (forest.lims[1] == "default") {
        if (class(x)[1] == "metacor"){
          min = min(sortdat.es$mean)-0.2
        } else {
          min = -0.2
        }

        max = max(sortdat.es$mean) + 0.5

      } else {
        min = forest.lims[1]
        max = forest.lims[2]
      }

      # Set ggtitles
      if (class(x)[1] == "metaprop"){
        ggtitl = as.character("Proportion")
      } else if (class(x)[1] == "metacor"){
        ggtitl = as.character("Correlation")
      } else {
        ggtitl = as.character("Rate")
      }


      ########################################
      cat("===============")
      ########################################

      title.es = with(sortdat.es, {
        paste0("hat(theta)['*']~'='~", paste0("'", format(round(mean, 2)), "'"),
               "~'['*", paste0("'", format(round(lower, 2), nsmall = 2), "'"), "*'-'*",
               paste0("'", format(round(upper, 2), nsmall = 2), "'"), "*']'*';'~italic(I)^2~'='~",
               paste0("'", format(round(i2, 2)*100,nsmall = 0), "'"), "*'%'")})

      title.i2 = with(sortdat.i2,{
        paste0("italic(I)^2~'='~",
               paste0("'", format(round(i2, 2)*100,nsmall = 0), "'"), "*'%'", "*';'~",
               "hat(theta)['*']~'='~", paste0("'", format(round(mean, 2)), "'"),
               "~'['*", paste0("'", format(round(lower, 2), nsmall = 2), "'"), "*'-'*",
               paste0("'", format(round(upper, 2), nsmall = 2), "'"), "*']'")})


      forest.es = ggplot(sortdat.es, aes(x = studlab, y = mean, ymin = lower, ymax = upper)) +
        geom_text(aes(label = title.es, y = Inf), parse = T, hjust = "inward", size = 3 * text.scale) +
        geom_hline(yintercept = 0, color = "blue") + ylab(paste(ggtitl, " (", as.character(lastline$studlab), ")", sep = "")) +
        ggtitle(paste("Sorted by", ggtitl)) +
        coord_flip() +
        theme_minimal() +
        theme(axis.title.y = element_blank(), axis.title.x = element_text(color = "black", size = 12, face = "bold"), axis.text.y = element_text(color = "black", size = 9 * text.scale), plot.title = element_text(face = "bold", hjust = 0.5), axis.line.x = element_line(color = "black"), axis.ticks.x = element_line(color = "black"), axis.text.x = element_text(color = "black", size = 9 * text.scale)) +
        scale_y_continuous(limits = c(min, max)) +
        geom_rect(aes(ymin=plot.sum.lower, ymax=plot.sum.upper, xmin=0, xmax=Inf), alpha=0.08, fill="lightgreen", color=NA) +
        geom_hline(yintercept = plot.sum.effect, color = "darkgreen", linetype="dotted", size=0.5) +
        geom_point(shape = 15, size = 4.5, color = "grey") +
        geom_linerange(size = 0.9) +
        geom_pointrange(shape = 3, size = 0.3)

      forest.i2 = ggplot(sortdat.i2, aes(x = studlab, y = mean, ymin = lower, ymax = upper)) +
        geom_text(aes(label = title.i2, y = Inf), parse = T, hjust = "inward", size = 3 * text.scale) +
        geom_hline(yintercept = 0, color = "blue") + ylab(paste(ggtitl, " (", as.character(lastline$studlab), ")", sep = "")) +
        ggtitle(expression(Sorted~by~italic(I)^2)) +
        coord_flip() +
        theme_minimal() +
        theme(axis.title.y = element_blank(), axis.title.x = element_text(color = "black", size = 12, face = "bold"), axis.text.y = element_text(color = "black", size = 9 * text.scale), plot.title = element_text(face = "bold", hjust = 0.5), axis.line.x = element_line(color = "black"), axis.ticks.x = element_line(color = "black"), axis.text.x = element_text(color = "black", size = 9 * text.scale)) +
        scale_y_continuous(limits = c(min, max)) +
        geom_rect(aes(ymin=plot.sum.lower, ymax=plot.sum.upper, xmin=0, xmax=Inf), alpha=0.08, fill="lightgreen", color=NA) +
        geom_hline(yintercept = plot.sum.effect, color = "darkgreen", linetype="dotted", size=0.5) +
        geom_point(shape = 15, size = 4.5, color = "grey") +
        geom_linerange(size = 0.9) +
        geom_pointrange(shape = 3, size = 0.3)



    } else {

        # Create Sortdat data set for sorting
        sortdat = data.frame(studlab = meta.inf$studlab, mean = meta.inf$TE, lower = meta.inf$lower, upper = meta.inf$upper,
            i2 = meta.inf$I2)
        sortdat2 = sortdat[1:(nrow(sortdat) - 2), ]
        lastline = sortdat[nrow(sortdat), ]

        # Change summary label
        if (random == TRUE) {
            lastline[1] = "Random-Effects Model"
        } else {
            lastline[1] = "Fixed-Effect Model"
        }

        for (i in 2:4) {
            lastline[i] = format(round(lastline[i], 2), nsmall = 2)
        }

        # Sort
        sortdat.es = sortdat2[order(sortdat2$mean), ]
        sortdat.es$studlab = factor(sortdat.es$studlab,
                                    levels = sortdat.es$studlab[order(-sortdat.es$mean)])
        sortdat.i2 = sortdat2[order(sortdat2$i2), ]
        sortdat.i2$studlab = factor(sortdat.i2$studlab,
                                    levels = sortdat.i2$studlab[order(-sortdat.i2$i2)])

        # Generate Forest Plots
        if (forest.lims[1] == "default") {
            min = round(min(sortdat.es$lower) - 0.1, 2)
            max = round(max(sortdat.es$upper) + 0.3, 2)
        } else {
            min = forest.lims[1]
            max = forest.lims[2]
        }

        if (method.meta == "fixed"){
          plot.sum.effect = x$TE.fixed
          plot.sum.lower = x$lower.fixed
          plot.sum.upper = x$upper.fixed
        } else {
          plot.sum.effect = x$TE.random
          plot.sum.lower = x$lower.random
          plot.sum.upper = x$upper.random
        }

        ########################################
        cat("===============")
        ########################################

        title.es = with(sortdat.es, {
                         paste0("hat(theta)['*']~'='~", paste0("'", format(round(mean, 2)), "'"),
                                "~'['*", paste0("'", format(round(lower, 2), nsmall = 2), "'"), "*'-'*",
                                paste0("'", format(round(upper, 2), nsmall = 2), "'"), "*']'*';'~italic(I)^2~'='~",
                                paste0("'", format(round(i2, 2)*100,nsmall = 0), "'"), "*'%'")})

        title.i2 = with(sortdat.i2,{
                          paste0("italic(I)^2~'='~",
                                 paste0("'", format(round(i2, 2)*100,nsmall = 0), "'"), "*'%'", "*';'~",
                                 "hat(theta)['*']~'='~", paste0("'", format(round(mean, 2)), "'"),
                                 "~'['*", paste0("'", format(round(lower, 2), nsmall = 2), "'"), "*'-'*",
                                 paste0("'", format(round(upper, 2), nsmall = 2), "'"), "*']'")})

        forest.es = ggplot(sortdat.es, aes(x = studlab, y = mean, ymin = lower, ymax = upper)) +
            geom_text(aes(label = title.es, y = Inf), parse = T, hjust = "inward", size = 3 * text.scale) + geom_hline(yintercept = 0,
            color = "blue") + ylim(min, max) + ylab(paste("Effect Size (", as.character(lastline$studlab),
            ")", sep = "")) + ggtitle("Sorted by Effect Size") + coord_flip() + theme_minimal() + theme(axis.title.y = element_blank(),
            axis.title.x = element_text(color = "black", size = 12, face = "bold"), axis.text.y = element_text(color = "black",
                size = 9 * text.scale), plot.title = element_text(face = "bold", hjust = 0.5), axis.line.x = element_line(color = "black"),
            axis.ticks.x = element_line(color = "black"), axis.text.x = element_text(color = "black", size = 9 *
                text.scale)) +
          geom_rect(aes(ymin=plot.sum.lower, ymax=plot.sum.upper, xmin=0, xmax=Inf), alpha=0.08, fill="lightgreen", color=NA) +
          geom_hline(yintercept = plot.sum.effect, color = "darkgreen", linetype="dotted", size=0.5) +
          geom_point(shape = 15, size = 4.5, color = "grey") +
          geom_linerange(size = 0.9) +
          geom_pointrange(shape = 3, size = 0.3)

        forest.i2 = ggplot(sortdat.i2, aes(x = studlab, y = mean, ymin = lower, ymax = upper)) +
          geom_text(aes(label = title.i2, y = Inf), parse = T, hjust = "inward", size = 3 * text.scale) + geom_hline(yintercept = 0,
          color = "blue") + ylim(min, max) + ylab(paste("Effect Size (", as.character(lastline$studlab), ")", sep = "")) +
          ggtitle(expression(Sorted~by~italic(I)^2)) + coord_flip() + theme_minimal() + theme(axis.title.y = element_blank(),
          axis.title.x = element_text(color = "black", size = 12, face = "bold"),
          axis.text.y = element_text(color = "black",size = 9 * text.scale), plot.title = element_text(face = "bold", hjust = 0.5),
          axis.line.x = element_line(color = "black"),
          axis.ticks.x = element_line(color = "black"), axis.text.x = element_text(color = "black", size = 9 * text.scale)) +
          geom_rect(aes(ymin=plot.sum.lower, ymax=plot.sum.upper, xmin=0, xmax=Inf), alpha=0.08, fill="lightgreen", color=NA) +
          geom_hline(yintercept = plot.sum.effect, color = "darkgreen", linetype="dotted", size=0.5) +
          geom_point(shape = 15, size = 4.5, color = "grey") +
          geom_linerange(size = 0.9) +
          geom_pointrange(shape = 3, size = 0.3)
    }


    # Generate baujat plot Define baujat.silent
    baujat.silent = function(x, yscale = 1, xlim, ylim, ...) {

        TE = x$TE
        seTE = x$seTE
        TE.fixed = metagen(TE, seTE, exclude = x$exclude)$TE.fixed
        k = x$k
        studlab = x$studlab
        SE = x$seTE

        m.inf = metainf(x, pooled = "fixed")
        TE.inf = m.inf$TE[1:length(TE)]
        seTE.inf = m.inf$seTE[1:length(TE)]

        ys = (TE.inf - TE.fixed)^2/seTE.inf^2
        ys = ys * yscale

        xs = (TE - TE.fixed)^2/seTE^2

        if (!is.null(x$exclude))
            xs[x$exclude] = 0



        res = data.frame(studlab = studlab, x = xs, y = ys, se = SE)


        return(res)
    }

    ########################################
    cat("===============")
    ########################################

    bjt = baujat.silent(x)

    BaujatPlot = ggplot(bjt, aes(x = x, y = y)) + geom_point(aes(size = (1/se)), color = "blue", alpha = 0.75) +
        geom_rug(color = "lightgray", alpha = 0.5) + theme(legend.position = "none") + xlab("Overall heterogeneity contribution") +
        ylab("Influence on pooled result") + geom_label_repel(label = bjt$studlab, color = "black", size = 1.5 *
        text.scale, alpha = 0.7)


    # Return

    ########################################
    cat("===============] DONE \n")
    ########################################

    # Prepare data for return
    return.data = cbind(sortdat2, cheungviechtdata[, 2:ncol(cheungviechtdata)], HetContrib = bjt$x, InfluenceEffectSize = bjt$y)

    if (x$sm %in% c("RR", "OR", "IRR")) {colnames(return.data)[1:2] = c("Author", effect)}
    else {colnames(return.data)[1:2] = c("Author", "effect")}

    returnlist = suppressWarnings(suppressMessages(list(BaujatPlot = BaujatPlot,
                      InfluenceCharacteristics = rma.influence.plot,
                      ForestEffectSize = forest.es,
                      ForestI2 = forest.i2,
                      Data = return.data)))

    if (return.separate.plots == T){class(returnlist) = c("InfluenceAnalysis", "rsp")}
    if (return.separate.plots == F){class(returnlist) = c("InfluenceAnalysis", "rsp.null")}

    returnlist

}



```


```{r eval = FALSE}
# Returns an error
meta1_inf <- InfluenceAnalysis(meta1, random = TRUE)
```

\newpage

## GOSH plot analysis 

```{r}
library(metafor)

### calculate r-to-z transformed correlations and corresponding sampling variances
df3 <- escalc(measure="ZCOR", ri=r, ni=n, data=df2)

### meta-analysis of the transformed correlations using a random-effects model
meta1_rma <- rma(yi = yi, 
                 vi = vi, 
                 data = df3)
meta1_rma

### average correlation with 95% CI
predict(meta1_rma, transf=transf.ztor)
```

```{r eval = FALSE}
# GOSH analysis  (time: ~ 1 day and 5 hours)
meta1_gosh <- gosh(meta1_rma) 
```
\newpage 

## Other ways to do outlier and influence analysis 

```{r}
# Baujat plot 
# https://www.metafor-project.org/doku.php/plots:baujat_plot
baujat(meta1_rma, xlim=c(0,20), ylim=c(0,0.2))
```

```{r eval= FALSE}
# https://www.dsquintana.blog/how-do-you-decide-which-studies-in-a-meta-analysis-are-influential-and-should-be-removed/
# https://www.metafor-project.org/doku.php/plots:plot_of_influence_diagnostics
inf <- influence(meta1_rma)
plot(inf, layout=c(8,1))
```

\newpage
## Forest plot 

```{r eval= FALSE}
pdf(file='forestplot.pdf', width = 10, height = 60)
forest.meta(meta1, 
            sortvar = r)
dev.off()
```

\newpage

## Drapery plots

Weird, not sure if it is using the z-transformed or if this plot does not work well with correlations. Values are over-bounds.

```{r}
drapery(meta1, 
        type = 'pval', 
        legend = FALSE)
```
\newpage

## Multilevel meta-analysis 

```{r}
library(metafor)

meta1_multi <- rma.mv(yi = yi, 
                      V = vi, 
                      random = list(~1 | study_id/es_id), 
                      data = df3)
summary(meta1_multi)
```



* Variance components: 
    + The between-study variance is sigma^2.1 = 0.0153 (equivalent to tau^2 in REM)- At this level we have 129 studies. 
    + The within-study variance is sigma^2.2 = 0.0041. At this level we have 273 effect sizes. 

* Estimate: 0.0906. However, this is a Fisher's z, so we have to transform the effect back to a normal correlation: 

```{r}
transf.ztor(meta1_multi$b)
```
* The correlation is approximately 0.09 which is a modest association 

* The test for heterogeneity rejects the null hypothesis of homogeneity, however this is not informative. Instead, we should look at the amount of heterogeneity caputred by each level in our model. 

\newpage

### Distribution of variance across levels 

Function: 
```{r}
#' Calculate I-squared values and variance distribution for multilevel meta-analysis models
#'
#' This function calculates values of \eqn{I^2} and the variance distribution for multilevel meta-analysis
#' models fitted with \code{\link[metafor]{rma.mv}}.
#'
#'
#' @usage mlm.variance.distribution(x)
#'
#' @param x An object of class \code{rma.mv}. Must be a multilevel model with two random effects (three-level meta-analysis model).
#'
#' @details This function estimates the distribution of variance in a three-level meta-analysis
#' model (fitted with the \code{\link[metafor]{rma.mv}} function). The share of variance attributable to
#' sampling error, within and between-cluster heterogeneity is calculated,
#' and an estimate of \eqn{I^2} (total and for Level 2 and Level 3) is provided. The function uses the formula by
#' Cheung (2014) to estimate the variance proportions attributable to each model component and to derive the \eqn{I^2} estimates.
#'
#'
#' @references
#'
#' Harrer, M., Cuijpers, P., Furukawa, T.A, & Ebert, D. D. (2019).
#' \emph{Doing Meta-Analysis in R: A Hands-on Guide}. DOI: 10.5281/zenodo.2551803. \href{https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/mlma.html}{Chapter 12}.
#'
#'Cheung, M. W. L. (2014). Modeling dependent effect sizes with three-level meta-analyses: a structural equation modeling approach. \emph{Psychological Methods, 19}(2), 211.
#'
#' @author Mathias Harrer & David Daniel Ebert
#'
#' @aliases var.comp
#'
#' @import ggplot2
#' @importFrom stats model.matrix
#'
#' @return Returns a data frame containing the results. A plot summarizing the variance distribution and \eqn{I^2} values can be generated using \code{plot}.
#'
#' @export mlm.variance.distribution
#' @export var.comp
#'
#' @examples
#' # Use dat.konstantopoulos2011 from the "metafor" package
#' library(metafor)
#'
#' # Build Multilevel Model (Three Levels)
#' m = rma.mv(yi, vi, random = ~ 1 | district/school, data=dat.konstantopoulos2011)
#'
#' # Calculate Variance Distribution
#' mlm.variance.distribution(m)
#'
#' # Use alias 'var.comp' and 'Chernobyl' data set
#' data("Chernobyl")
#' m2 = rma.mv(yi = z, V = var.z, data = Chernobyl, random = ~ 1 | author/es.id)
#' res = var.comp(m2)
#'
#' # Print results
#' res
#'
#' # Generate plot
#' plot(res)



mlm.variance.distribution = var.comp = function(x){

  m = x

  # Check class
  if (!(class(m)[1] %in% c("rma.mv", "rma"))){
    stop("x must be of class 'rma.mv'.")
  }

  # Check for three level model
  if (m$sigma2s != 2){
    stop("The model you provided does not seem to be a three-level model. This function can only be used for three-level models.")
  }

  # Check for right specification (nested model)
  if (sum(grepl("/", as.character(m$random[[1]]))) < 1){
    stop("Model must contain nested random effects. Did you use the '~ 1 | cluster/effect-within-cluster' notation in 'random'? See ?metafor::rma.mv for more details.")
  }

  # Get variance diagonal and calculate total variance
  n = m$k.eff
  vector.inv.var = 1/(diag(m$V))
  sum.inv.var = sum(vector.inv.var)
  sum.sq.inv.var = (sum.inv.var)^2
  vector.inv.var.sq = 1/(diag(m$V)^2)
  sum.inv.var.sq = sum(vector.inv.var.sq)
  num = (n-1)*sum.inv.var
  den = sum.sq.inv.var - sum.inv.var.sq
  est.samp.var = num/den

  # Calculate variance proportions
  level1=((est.samp.var)/(m$sigma2[1]+m$sigma2[2]+est.samp.var)*100)
  level2=((m$sigma2[2])/(m$sigma2[1]+m$sigma2[2]+est.samp.var)*100)
  level3=((m$sigma2[1])/(m$sigma2[1]+m$sigma2[2]+est.samp.var)*100)

  # Prepare df for return
  Level=c("Level 1", "Level 2", "Level 3")
  Variance=c(level1, level2, level3)
  df.res=data.frame(Variance)
  colnames(df.res) = c("% of total variance")
  rownames(df.res) = Level
  I2 = c("---", round(Variance[2:3], 2))
  df.res = as.data.frame(cbind(df.res, I2))

  totalI2 = Variance[2] + Variance[3]


  # Generate plot
  df1 = data.frame("Level" = c("Sampling Error", "Total Heterogeneity"),
                  "Variance" = c(df.res[1,1], df.res[2,1]+df.res[3,1]),
                  "Type" = rep(1,2))

  df2 = data.frame("Level" = rownames(df.res),
                   "Variance" = df.res[,1],
                   "Type" = rep(2,3))

  df = as.data.frame(rbind(df1, df2))


  g = ggplot(df, aes(fill=Level, y=Variance, x=as.factor(Type))) +
    coord_cartesian(ylim = c(0,1), clip = "off") +
    geom_bar(stat="identity", position="fill", width = 1, color="black") +
    scale_y_continuous(labels = scales::percent)+
    theme(axis.title.x=element_blank(),
          axis.text.y = element_text(color="black"),
          axis.line.y = element_blank(),
          axis.title.y=element_blank(),
          axis.line.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.text.x = element_blank(),
          axis.ticks.y = element_line(lineend = "round"),
          legend.position = "none",
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          legend.background = element_rect(linetype="solid",
                                           colour ="black"),
          legend.title = element_blank(),
          legend.key.size = unit(0.75,"cm"),
          axis.ticks.length=unit(.25, "cm"),
          plot.margin = unit(c(1,3,1,1), "lines")) +
    scale_fill_manual(values = c("darkseagreen3", "deepskyblue3", "darkseagreen2",
                                 "deepskyblue1", "deepskyblue2")) +

    # Add Annotation

    # Total Variance
    annotate("text", x = 1.5, y = 1.05,
             label = paste("Total Variance:",
                           round(m$sigma2[1]+m$sigma2[2]+est.samp.var, 3))) +

    # Sampling Error
    annotate("text", x = 1, y = (df[1,2]/2+df[2,2])/100,
             label = paste("Sampling Error Variance: \n", round(est.samp.var, 3)), size = 3) +

    # Total I2
    annotate("text", x = 1, y = ((df[2,2])/100)/2-0.02,
             label = bquote("Total"~italic(I)^2*":"~.(round(df[2,2],2))*"%"), size = 3) +
    annotate("text", x = 1, y = ((df[2,2])/100)/2+0.05,
             label = paste("Variance not attributable \n to sampling error: \n", round(m$sigma2[1]+m$sigma2[2],3)), size = 3) +

    # Level 1
    annotate("text", x = 2, y = (df[1,2]/2+df[2,2])/100, label = paste("Level 1: \n",
                                                                       round(df$Variance[3],2), "%", sep=""), size = 3) +

    # Level 2
    annotate("text", x = 2, y = (df[5,2]+(df[4,2]/2))/100,
             label = bquote(italic(I)[Level2]^2*":"~.(round(df[4,2],2))*"%"), size = 3) +

    # Level 3
    annotate("text", x = 2, y = (df[5,2]/2)/100,
             label = bquote(italic(I)[Level3]^2*":"~.(round(df[5,2],2))*"%"), size = 3)

  returnlist = list(results = df.res,
                    totalI2 = totalI2,
                    plot = g)
  class(returnlist) = c("mlm.variance.distribution", "list")

  invisible(returnlist)

  returnlist

}


```

```{r}
i_squared <- var.comp(meta1_multi)
i_squared
```

* The sampling error variance at level 1 is small, making up about 4% of the total variance.

* I^2 at level 2 is about 20%. This is the amount of heterogeneity variance within clusters. 

* I^2 at level 3 is about 75%. This is the amount  of between-study heterogeneity. 

\newpage

### Comparing models 

```{r}
meta1_2level <- rma.mv(yi = yi, 
                      V = vi, 
                      random = list(~1 | study_id/es_id), 
                      data = df3,
                      sigma2 = c(0, NA))
summary(meta1_2level)

anova(meta1_multi, meta1_2level)
```

The three-level model has better fit: AIC and BIC are lower for the 3-level model and the LRT is significant 





\newpage

# Meta-analysis 2: hakn = TRUE

Change from Meta-analysis 1 only one thing: 

* Apply the hakn correction to control for the uncertainty in our estimate of the between-study heterogeneity. 

```{r}
meta2 <- metacor(cor = r, 
                 n = n, 
                 studlab = reference, 
                 data= df2, 
                 fixed = FALSE, 
                 random = TRUE, 
                 method.tau = 'REML', 
                 hakn = TRUE, 
                 title = "Mindset and Academic Achievement")
meta2
```

Conclusion: The confidence interval is slightly larger than meta1, and the test is based on a t-distribution instead of a z-distribution. The estimate stays the same. 

Applying the correction does not change any conclusion, so I will not apply it in subsequent analyses. 

\newpage

#  Meta-analysis 3: method.tau = 'DL'
```{r}
meta3 <- metacor(cor = r, 
                 n = n, 
                 studlab = reference, 
                 data= df2, 
                 fixed = FALSE, 
                 random = TRUE, 
                 method.tau = 'DL', 
                 hakn = FALSE, 
                 title = "Mindset and Academic Achievement")
meta3
```

\newpage

#  Meta-analysis 4: method.tau = 'PM'
```{r}
meta4 <- metacor(cor = r, 
                 n = n, 
                 studlab = reference, 
                 data= df2, 
                 fixed = FALSE, 
                 random = TRUE, 
                 method.tau = 'PM', 
                 hakn = FALSE, 
                 title = "Mindset and Academic Achievement")
meta4
```

\newpage

#  Meta-analysis 5: method.tau = 'EB'
```{r}
meta5 <- metacor(cor = r, 
                 n = n, 
                 studlab = reference, 
                 data= df2, 
                 fixed = FALSE, 
                 random = TRUE, 
                 method.tau = 'EB', 
                 hakn = FALSE, 
                 title = "Mindset and Academic Achievement")
meta5
```

\newpage

#  Meta-analysis 6: method.tau = 'SJ'
```{r}
meta6 <- metacor(cor = r, 
                 n = n, 
                 studlab = reference, 
                 data= df2, 
                 fixed = FALSE, 
                 random = TRUE, 
                 method.tau = 'SJ', 
                 hakn = FALSE, 
                 title = "Mindset and Academic Achievement")
meta6
```
